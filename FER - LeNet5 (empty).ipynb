{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bjABFHaB6JjH"
   },
   "source": [
    "# Problema de clasificación de emociones por expresiones faciales\n",
    "\n",
    "A lo largo de este notebook explicaré cómo utilizar el poder del cómputo en la nube a través de Google CoLab para resolver el siguiente problema: clasificar emociones mediante expresiones faciales.\n",
    "\n",
    "Para este problema de clasificación, utilizaremos una arquitectura basada en LeNet-5 ([*LeCunn et. al, 1998*](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf)), una arquitectura de Red Neuronal Convolucional (CNN, Convolutional Neural Network) que se describirá en un momento.\n",
    "\n",
    "El paquete principal de Python que estaremos utilizando será [Keras](https://keras.io/).\n",
    "\n",
    "\n",
    "### Planteamiento del problema\n",
    "\n",
    "Antes de atacar el problema con una CNN, entendamos lo que estaremos realizando: Si capturamos la imagen del rostro de una persona, queremos ser capaces de determinar la emoción evocada a través de la expresión facial.\n",
    "\n",
    "\n",
    "#### ¿Qué necesitamos hacer?\n",
    "\n",
    "Entrenar un modelo de aprendizaje profundo (en este caso) utilizando una base de datos propia: `FER_CIMAT_DATASET` (*Mitre & Mitre, 2018.*).\n",
    "\n",
    "\n",
    "#### > La base de datos de rostros < (*Ver muestras de la misma.*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QYAMUuYU8l7r"
   },
   "source": [
    "# Pre-procesamiento de los datos\n",
    "\n",
    "#### Buenas noticias:\n",
    "\n",
    "El corpus de la base de datos `FER_CIMAT_DATASET`, por su naturaleza, no requiere un tratamiento previo de modificación a la imagen. De cualquier manera, las imágenes han sido re-escaladas para el modelo de entrenamiento.\n",
    "\n",
    "Sólo necesitamos importar la base de datos utilizando `PyDrive` y dividir los datos en conjuntos de prueba y de entrenamiento (para posteriormente poder realizar las evaluaciones de precisión).\n",
    "\n",
    "Para instalar `PyDrive` en Google CoLab corremos el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "BCH97Q7r5-pE"
   },
   "outputs": [],
   "source": [
    "!pip install -U -q PyDrive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zKnmSIf8-LJ3"
   },
   "source": [
    "### Importando los datos:\n",
    "\n",
    "Posterior a ello, importamos los paquetes necesarios y creamos los autenticadores de los archivos en Google Drive, para posteriormente importar los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "mWD6PsF_-KIE"
   },
   "outputs": [],
   "source": [
    "# Importamos paquetería para trabajar sobre Google Drive:\n",
    "from oauth2client.client import GoogleCredentials\n",
    "from pydrive.drive import GoogleDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from google.colab import files\n",
    "from google.colab import auth\n",
    "import pickle\n",
    "\n",
    "# Autenticamos nuestra cuenta en Google Drive (para obtener los datos):\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "# Insertamos los identificadores de los archivos:\n",
    "x_id = '1Zuq_y1Xy5W-pPtFnvPGeMvy_jRqbZr3y'\n",
    "y_id = '1LQAYnBPwccXDJ6mUS1T-Nj21NvGWZTLg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qo5BatML-zvT"
   },
   "source": [
    "Ahora podemos importar desde Google Drive (de manera remota) los archivos a utilizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "b8DJoNYx-y_J"
   },
   "outputs": [],
   "source": [
    "# Etiquetas de emociones:\n",
    "y_file = drive.CreateFile({'id': y_id})\n",
    "y_file.GetContentFile(\"y.dat\")\n",
    "y_raw = pickle.load(open(\"y.dat\", \"rb\"))\n",
    "\n",
    "# Emociones en crudo:\n",
    "x_file = drive.CreateFile({'id': x_id})\n",
    "x_file.GetContentFile(\"X.dat\")\n",
    "x_raw = pickle.load(open(\"X.dat\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UpYu3ZBH__iB"
   },
   "source": [
    "### Pre-procesando los datos:\n",
    "\n",
    "Procedemos a dividir los datos en conjuntos de entrenamiento y prueba como sigue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qgsKnF_t_twC",
    "outputId": "14077f87-ce0b-4a1c-c58c-fb137503da5d"
   },
   "outputs": [],
   "source": [
    "# Importamos paquetes auxiliares:\n",
    "from sklearn.utils import shuffle\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Definimos parámetros de los datos:\n",
    "# random_state = random.randint(1, 50)\n",
    "random_state = 11\n",
    "print(random_state)\n",
    "train_split = .9\n",
    "num_classes = 8\n",
    "\n",
    "# Mezclamos por clases:\n",
    "unique_values, indexes, counts = np.unique(y_raw, return_index=True, return_counts=True)\n",
    "\n",
    "x_train, y_train, x_test, y_test = [], [], [], []\n",
    "\n",
    "for value, index, count in zip(unique_values, indexes, counts):\n",
    "    # Tomamos valores:\n",
    "    x_values = x_raw[index:index+count]\n",
    "    y_values = y_raw[index:index+count]\n",
    "\n",
    "    # Mezclamos los datos:\n",
    "    x_values, y_values = shuffle(x_values, y_values, random_state=random_state)\n",
    "    \n",
    "    # Dividimos los datos:\n",
    "    longitud = int(len(x_values)*train_split)\n",
    "    x_train.extend(x_values[:longitud])\n",
    "    y_train.extend(y_values[:longitud])\n",
    "    x_test.extend(x_values[longitud:])\n",
    "    y_test.extend(y_values[longitud:])\n",
    "\n",
    "\n",
    "# Vectorizamos:\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FAQK_V5WBbnS"
   },
   "source": [
    "Procedemos a obtener las dimensiones de los datos, así como a cada etiqueta convertirla en vector categórico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "91U0LSlyBK6x",
    "outputId": "286431de-b52d-49e4-a224-d29b6ab079e8"
   },
   "outputs": [],
   "source": [
    "# Obtener dimensiones:\n",
    "img_height, img_width, channels = x_train.shape[1], x_train.shape[2], x_train.shape[3]\n",
    "print(\"Dimensiones de imagen: {}x{}\".format(img_height, img_width))\n",
    "print(\"Número de canales: {}\".format(channels))\n",
    "\n",
    "# Convertir a \"one hot encoding\":\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_99lnw0yCfQ1"
   },
   "source": [
    "Ahora sí, comienza lo bueno.\n",
    "\n",
    "## Hablemos sobre el modelo...\n",
    "\n",
    "Utilizaremos un modelo basado en LeNet-5, que es una CNN con la siguiente arquitectura:\n",
    "\n",
    "![LeNet-5](https://raw.githubusercontent.com/RodolfoFerro/MeetupHCC18/master/more/LeNet-5.png)\n",
    "Fuente: ([*\"Gradient-Based Learning Applied to Document Recognition\", LeCunn et. al, 1998*](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf))\n",
    "\n",
    "## ¡A armar el modelo!\n",
    "\n",
    "Primero importemos todo lo que utilizaremos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ZnDICxYyB8Nt"
   },
   "outputs": [],
   "source": [
    "# Importemos nuestro contenido desde Keras:\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xnmQLS4mEOyC"
   },
   "source": [
    "Y definamos la arquitectura a partir de un modelo secuencial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Nsyk2jlUEN3n"
   },
   "outputs": [],
   "source": [
    "def LeNet5_pero_tuneado(input_shape=(img_height, img_width, channels)):\n",
    "    \"\"\"Modelo de CNN basado en LeNet-5.\"\"\"\n",
    "    \n",
    "    # Creamos el modelo:\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Añadir capa convolucional (30, 5x5, relu) - input_shape\n",
    "    # Añadir max-pool (2x2)    \n",
    "    \n",
    "    # Añadir capa convolucional (15, 3x3, relu)\n",
    "    # Añadir max-pool (2x2)\n",
    "    \n",
    "    # Añadir dropout\n",
    "    # Añadir flatten\n",
    "    \n",
    "    # Añadir FC (100, relu)\n",
    "    # Añadir FC (50, relu)\n",
    "    # Añadir FC (num_classes, softmax)\n",
    "    \n",
    "    # Compilamos el modelo:\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oNInMCP8FDZN"
   },
   "source": [
    "### Nuestra arquitectura:\n",
    "\n",
    "![Aquí debería haber una imagen...](https://raw.githubusercontent.com/RodolfoFerro/MeetupHCC18/master/more/model.svg)\n",
    "\n",
    "#### Rcursos útiles:\n",
    "\n",
    "- Modelo secuencial en Keras: https://keras.io/getting-started/sequential-model-guide/\n",
    "- ¿Qué es *Dropout*?: http://jmlr.org/papers/v15/srivastava14a.html\n",
    "\n",
    "### Armamos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "C4AyIcgUFAaG",
    "outputId": "cf4a3328-9997-4831-d11d-76ae34a095e5"
   },
   "outputs": [],
   "source": [
    "# Armamos el modelo:\n",
    "model = LeNet5_pero_tuneado()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EYQi1TqpFklw"
   },
   "source": [
    "### Entrenamos el modelo:\n",
    "\n",
    "Para ello, definiemos los hiperparámetros de entrenamiento.\n",
    "\n",
    "(**No olvidar cambiar el *'runtime'* por GPU para liberar el poder de las tarjetas gráficas de Google...**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "1V35fTCMFhyf",
    "outputId": "4531f0f4-6990-4c6c-f43d-5e2ca937a377"
   },
   "outputs": [],
   "source": [
    "# Definimos hiperparámetros:\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "# Entrenamos el modelo:\n",
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), \n",
    "          epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y3vpC3KdIgIi"
   },
   "source": [
    "### Evaluamos los resultados:\n",
    "\n",
    "Para ello imprimimos los resultados sobre los datos de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "tN7Dcyz-KVFE",
    "outputId": "0da369e8-bea6-4f8e-a94d-92360d6a8f8b"
   },
   "outputs": [],
   "source": [
    "# Evaluación final del modelo:\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Precisión sobre conjunto de prueba:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LBBDjURXKjVT"
   },
   "source": [
    "Más aún, podemos ver el proceso de aprendizaje a lo largo del tiempo. Para ello creamos un par de funciones para visualizar dicho proceso de aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Jv1u-yxNFvpr"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_loss(history, path):\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(\"Model's training loss\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.savefig(path)\n",
    "\n",
    "\n",
    "def plot_acc(history, path):\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title(\"Model's training acc\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.savefig(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 579
    },
    "colab_type": "code",
    "id": "v_ivcL2ZH3eC",
    "outputId": "f1aa09af-2fc3-456e-b75e-ac8e077c27a5"
   },
   "outputs": [],
   "source": [
    "# Plot loss and accuracy:\n",
    "plot_acc(history, 'model_accuracy.png')\n",
    "plot_loss(history, 'model_loss.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TMF3qkhNL2al"
   },
   "source": [
    "### Guardamos archivos:\n",
    "\n",
    "Y para guardar los archivos generados en Google Drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "C33PuyMuLXph",
    "outputId": "f8214d11-14e0-4ac5-80f9-27f3d0c68b1c"
   },
   "outputs": [],
   "source": [
    "# Guardamos los archivos generados:\n",
    "files.download('model_accuracy.png')\n",
    "files.download('model_loss.png')\n",
    "\n",
    "# Subimos los archivos generados a Google Drive:\n",
    "uploaded = drive.CreateFile({'title': 'model_accuracy.png'})\n",
    "uploaded.SetContentFile(\"model_accuracy.png\")\n",
    "uploaded.Upload()\n",
    "print('Archivo subido con ID: {}'.format(uploaded.get('id')))\n",
    "\n",
    "uploaded = drive.CreateFile({'title': 'model_loss.png'})\n",
    "uploaded.SetContentFile(\"model_loss.png\")\n",
    "uploaded.Upload()\n",
    "print('Archivo subido con ID: {}'.format(uploaded.get('id')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8N2hiwpL-WbB",
    "outputId": "abd7b930-45bf-41a5-e75d-17296cd90f61"
   },
   "outputs": [],
   "source": [
    "# Serializar modelo a JSON:\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# Serializar pesos a HDF5 (se necesita h5py):\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Modelo guardado en disco.\")\n",
    "\n",
    "files.download('model.json')\n",
    "files.download('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B-m230kO_ZBs"
   },
   "source": [
    "### Cargamos modelos:\n",
    "\n",
    "Básicamente hacemos dos cosas:\n",
    "1. Cargamos el modelo desde un archivo JSON.\n",
    "2. Cargamos los pesos desde un archivo HDF5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "94vVQrKt_iUQ"
   },
   "outputs": [],
   "source": [
    "# Cargamos json y creamos el modelo:\n",
    "from keras.models import model_from_json\n",
    "\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# Cargamos pesos al modelo:\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "name": "FER - LeNet5.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "318px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
